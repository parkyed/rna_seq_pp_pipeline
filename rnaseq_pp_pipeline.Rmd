---
title: "RNA-Seq Count Data Pre-Processing Pipeline: Testing with Protect Dataset"
author: "Ed Parkinson"
date: "31/03/2025"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Libraries and scripts

```{r}

here::i_am("rnaseq_pp_pipeline.Rmd")

```

```{r}

library(here)
library(tidyverse)
library(stats)        # contains functions for curve smoothing - approxfun approx smooth.spline
library(reshape2)     # data manipulation, including melt function
library(ggrepel)      # chart labelling
library(wdm)          # alternative for Hoeffding's D statistic with implementation in O(n log n) time
library(DESeq2)       # median ratio and vst transformations
library(xtable)      # creating latex tables

#library(HTSFilter)    # for independent filtering with HTS approach
# library(docstring)    # docstring information
# library(dgof)         # required package for Kolmogorov-Smirnov statistic Ka

```

```{r source scripts used in pipeline}

# source functions contained in scripts

source(here("scr", "rnaSeqQAPipeline.R"))
source(here("scr", "l1DistBar.R"))
source(here("scr", "l1DistMatrix.R"))
source(here("scr", "l1DistOutliers.R"))
source(here("scr", "calcKS.R"))
source(here("scr", "ksBar.R"))
source(here("scr", "ksOutliers.R"))
source(here("scr", "dStatBar.R"))
source(here("scr", "dStatOutliers.R"))
source(here("scr", "maCalc.R"))
source(here("scr", "maPlots.R"))
source(here("scr", "pcaScatterAnnotated.R"))
source(here("scr", "pcaScreePlot.R"))
source(here("scr", "colours.R"))
source(here("scr", "loadRData.R"))

```

## Define dataset to QA

```{r}

dset <- "protect_v4" ## FIXME
dset.data.path <- "/Users/ep/Documents/1_datasets/dataset_pearth/an0304/output/v2/" ## FIXME

dir_name <- here("qa_image_out", dset)

# Check if the directory exists, and create it if it doesn't
if (!dir.exists(dir_name)) {
  dir.create(dir_name, recursive = TRUE)
  message("Directory created: ", dir_name)
} else {
  message("Directory already exists: ", dir_name)
}

```

## Raw Data Import

Input data required for the QA pipeline:

*Normalised counts - p x n matrix of rna-seq count data, with p genes as rows and n samples as columns, after median-ratio scaling
*vst transformed counts
*sample information - data frame of meta data, including the class labels / diagnosis ('condition'), with n rows, corresponding to the samples.

```{r import raw data}

## read the sample information file, and ensure sorted by analysisID
## read input counts data and reorder columns to match the sample information

sample.info <- read.table(file = paste(dset.data.path, "targets_preprocessed.csv", sep=""), sep = ",", header = T, check.names = F) %>%
  arrange(analysisID)

counts.mat <- loadRData(file = paste(dset.data.path, "raw_counts.RData", sep=""))

counts.mat <- counts.mat[sample.info$analysisID]

if(!identical(colnames(counts.mat), sample.info$analysisID)){stop()}


# define vector of columns in the sample information file that will be used to annotate QA images and should be converted to factors (e.g. patient condition)

annotation.list = c("library_batch", "condition") ### FIXME ###

# convert annotation list and columns to factors

sample.info[annotation.list] <- lapply(sample.info[annotation.list], factor)

# view sample information table

glimpse(sample.info)
sample.info[1:10, 1:10]
sample.info %>% dim
counts.mat %>% dim
counts.mat[1:10, 1:10]
```


## Median - Ratio Normalisation with DESeq2

Scale the raw counts to compensate for differences in sequence depth and sample composition between samples.
Transform with variance stabilising transformation (or rlog transfrmation) to make data homoskedastic and reduce zero-inflation

```{r median-ratio scaling}

# create DESeq Data Set object from the raw counts (converted to a matrix), with condition as the factor of interest

dds <- DESeq2::DESeqDataSetFromMatrix(
    countData = as.matrix(counts.mat),
    colData = data.frame(sample.info, row.names = 'analysisID'),
    design = ~ condition)
  
# calculate the normalised count values using the median-of-ratios method

dds <- dds %>% DESeq2::estimateSizeFactors()

# extract raw and noramliseed counts as matrix

raw.counts     <- counts(dds, normalized = FALSE)

norm.counts    <- counts(dds, normalized = TRUE)

# vst tranform the counts

vst.counts <- DESeq2::varianceStabilizingTransformation(dds, blind=FALSE) %>% assay

```

## Run QA Pipeline

```{r}

# test datasets

# norm.counts.test <- norm.counts[1:10000,]
# vst.counts.test <- vst.counts[1:10000,]

outlier.lst <- rnaSeqQAPipeline(norm.counts,
                                vst.counts,
                                sample.info,
                                annotation_list = annotation.list,
                                out_dir = here("qa_image_out", dset),
                                ma_topx = 10,
                                n_samp = 10000,
                                pqual = 500)

```

## outlier dataframe

```{r}

outlier.lst %>% unlist %>% names %>% unique %>% sort

out.lst <- unique(c(names(outlier.lst$l1), names(outlier.lst$ks), names(outlier.lst$dstat))) %>% 
  sort

outlier.df <- data.frame(
  SampleID = out.lst,
  L1 = if_else(out.lst %in% names(outlier.lst$l1), "x", ""),
  KS = if_else(out.lst %in% names(outlier.lst$ks), "x", ""),
  D = if_else(out.lst %in% names(outlier.lst$dstat), "x", "")
)


print(outlier.df.xtable <- xtable(outlier.df),include.rownames = FALSE, include.colnames = TRUE, sanitize.text.function = I, hline.after = c(0))


```



Testing labelling outliers in the output bar charts

```{r}

## L1 bar chart modification

mat.dist.matrix <- l1DistanceMatrix(norm.counts) # [find a faster function for this]

l1.metrics <- l1DistOutliers(mat.dist.matrix)

l1DistBar(targets = sample.info, metrics = l1.metrics, annotation = "condition")
l1DistBar(targets = sample.info, metrics = l1.metrics, annotation = "library_batch")

annotation.list

l1.metrics$l1.outlier.threshold

l1.plot.data <- data.frame(sample.info %>% dplyr::select(analysisID, condition),
                             'SumDist' = l1.metrics$sum.dist)
  
  ggplot(l1.plot.data, aes(x=reorder(analysisID, SumDist), y = SumDist, fill=get(names(l1.plot.data)[2]))) +
    geom_bar(stat='identity') +
    coord_flip() +
    theme(legend.title = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank()) +
    xlab("SampleID") + 
    ylab("Sum of L1 Distance") + 
    scale_y_continuous(limits = c(-7 , (max(l1.plot.data$SumDist) *1.05))) +
    geom_hline(yintercept = l1.metrics$l1.outlier.threshold) +
    scale_fill_manual(values = cbp1) +
    
    geom_point(data = l1.plot.data %>% dplyr::filter(SumDist > l1.metrics$l1.outlier.threshold),
               aes(x = analysisID, y = -1), shape = 8, show.legend = F) + 
    annotate(geom = "text",
             x = l1.plot.data %>% dplyr::filter(SumDist > l1.metrics$l1.outlier.threshold) %>% .$analysisID,
             y = -2,
             hjust = 1,
             size = 3,
             colour = "red",
             label = l1.plot.data %>% dplyr::filter(SumDist > l1.metrics$l1.outlier.threshold) %>% .$analysisID) + 
    annotate(geom = "text",
             x = l1.plot.data %>% dplyr::filter(SumDist <= l1.metrics$l1.outlier.threshold) %>% .$analysisID,
             y = -2,
             hjust = 1,
             size = 3,
             colour = "black",
             label = l1.plot.data %>% dplyr::filter(SumDist <= l1.metrics$l1.outlier.threshold) %>% .$analysisID)
  
  
```

KS Bar

```{r}

## ks bar chart modification
  
k.stats <- calcKS(norm.counts)
  k.stats
dist.outliers <- ksOutliers(k.stats)
dist.outliers$threshold

  ks.plot.data <- left_join(sample.info %>% dplyr::select(analysisID, condition),
                            k.stats, 
                            by = join_by(analysisID))

  # ks.plot.data <- data.frame(sample.info %>% dplyr::select(analysisID, condition),
  #                            'k_stat' = metrics$k_stat)
  
  
  (ks.barchart <- ggplot(ks.plot.data, aes(x=reorder(analysisID, k_stat), y = k_stat, fill=get(names(ks.plot.data)[2]))) +
    geom_bar(stat='identity') +
    coord_flip() +
    ggtitle("Ranked K-S Statistic") + 
    xlab("sampleID") + 
    ylab("k-s statistic") + 
    theme(legend.title = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank()) +
    geom_hline(yintercept = dist.outliers$threshold) +
    scale_fill_manual(values = cbp1) +
    scale_y_continuous(limits = c(-0.04 , (max(ks.plot.data$k_stat) *1.05))) +
    geom_point(data = ks.plot.data %>% dplyr::filter(k_stat > dist.outliers$threshold),
         aes(x = analysisID, y = -0.01), shape = 8, show.legend = F) + 
    annotate(geom = "text",
             x = ks.plot.data %>% dplyr::filter(k_stat > dist.outliers$threshold) %>% .$analysisID,
             y = -0.02,
             hjust = 1,
             size = 3,
             colour = "red",
             label = ks.plot.data %>% dplyr::filter(k_stat > dist.outliers$threshold) %>% .$analysisID) + 
    annotate(geom = "text",
             x = ks.plot.data %>% dplyr::filter(k_stat  <= dist.outliers$threshold) %>% .$analysisID,
             y = -0.02,
             hjust = 1,
             size = 3,
             colour = "black",
             label = ks.plot.data %>% dplyr::filter(k_stat  <= dist.outliers$threshold) %>% .$analysisID)
  )
 
   
ksBar(sample.info, k.stats, dist.outliers, "library_batch")

```

Dstat bar

```{r}

d.stats <- dStatOutliers(vst.counts)
targets <- sample.info  
metrics <- d.stats

  (dstat.plot.data <- data.frame(targets %>% dplyr::select(analysisID, condition), # condition
                                'd_stat' = metrics$d.stats)
  )

  (d.stat.barplot <- ggplot(dstat.plot.data, aes(x=reorder(analysisID, d_stat), y = d_stat, fill=get(names(dstat.plot.data)[2]))) +
    geom_bar(stat='identity') + 
    coord_flip() +
    ggtitle("Hoeffding's D-statistic on joint dist. of M and A values") + 
    xlab("sampleID") + 
    ylab("Hoeffding's D-statistic") + 
    theme(legend.title = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank()) +
    geom_hline(yintercept = metrics$dstat.outlier.threshold) +
    scale_fill_manual(values = cbp1) +
    scale_y_continuous(limits = c(-0.01 , (max(dstat.plot.data$d_stat) *1.05))) +
    geom_point(data = dstat.plot.data %>% dplyr::filter(d_stat > metrics$dstat.outlier.threshold),
         aes(x = analysisID, y = -0.005), shape = 8, show.legend = F) + 
    annotate(geom = "text",
             x = dstat.plot.data %>% dplyr::filter(d_stat > metrics$dstat.outlier.threshold) %>% .$analysisID,
             y = -0.005,
             hjust = 1,
             size = 3,
             label = dstat.plot.data %>% dplyr::filter(d_stat >metrics$dstat.outlier.threshold) %>% .$analysisID)
  )

dStatBar(sample.info, d.stats, "library_batch")

```


Testing MA plots output

```{r}

d.stats <- dStatOutliers(vst.counts)
targets <- sample.info  
metrics <- d.stats
n_samp <- 5000

ma.plot.tst <- maPlots(vst.counts = vst.counts,
                   targets = sample.info, 
                   metrics = d.stats, 
                   annotation = "condition", 
                   top_x= 10, 
                   bottom_x= 10, 
                   subsample = n_samp)


ma.plot.tst

```

Testing PCA plots with elipses:

```{r}

# pcaScatterAnnotatedTEST <- function(pca_results, targets, annotation) {
  
  #' Generate a 2D scatter plot of the first two PCs, annotated with a given column in the phenotype data
  #'
  #' @param pca_results the matrix of eigen values output from the PCA cacluation
  #' @param targets the targets matrix
  #' @param annotation The the name of the column in the targets dataframe used to annotate plot
  
targets <- sample.info
annotation <- "condition"
pca_results <- stats::prcomp(t(vst.counts), center = TRUE, scale = FALSE, rank = 9)

  annotation <- enquo(annotation)  
  
  ## compute the variance explained by each PC for the n PCs calculated
  pca_var_explained <- (pca_results$sdev^2/sum(pca_results$sdev^2))
  
  ## Scatter plots of pairs of principle components
  pca_results_merged <- pca_results$x %>%
    as_tibble(rownames = "analysisID") %>%
    merge(targets, by="analysisID",  sort=FALSE)    # may need to left join this...

  # calculate centroids
  controids.df <- pca_results_merged %>% dplyr::select(PC1, PC2, condition)

  (centroids.df <- pca_results_merged %>% dplyr::select(PC1, PC2, !!annotation))
  colnames(centroids.df) <- c("PC1", "PC2", "anno")
  centroids <- aggregate(cbind(PC1, PC2)~anno,centroids.df,mean)

  pca_plot <- ggplot(pca_results_merged, aes(x=PC1,y=PC2)) +
    geom_point(aes(color=(!!annotation)),size=4) +
    geom_point(data = centroids, size = 5) +
    theme_bw(base_size=32) +
    labs(x=paste0("PC1: ",round(pca_var_explained[1]*100,1),"%"),
         y=paste0("PC2: ",round(pca_var_explained[2]*100,1),"%"),
         color = element_blank()) +
    theme(legend.position="bottom",
          legend.margin=ggplot2::margin(-5,-5,-5,-5),
          legend.box.margin=ggplot2::margin(-5,-5,-5,-5),
          axis.text=element_text(size=18),
          axis.title=element_text(size=18),
          plot.title=element_text(size=18),
          legend.text=element_text(size=18),
          legend.title=element_text(size=18)) +
    stat_ellipse(aes(color=(!!annotation)), level = 0.85) +
    scale_colour_manual(values = cbp1)

  pca_plot
  # excluded from function

  # geom_text_repel(aes(label = analysisID),
  #                 size = 3,
  #                 box.padding   = 0.15,
  #                 point.padding = 0.25,
  #                 segment.color = 'grey50')
  
#   return(pca_plot)
# }



pca_results <- stats::prcomp(t(vst.counts), center = TRUE, scale = FALSE, rank = 9)
pcaScatterAnnotatedTEST(pca_results = pca_results, targets = sample.info, annotation = condition)

```

